
# Imports
from config import *
import stouputils as stp
import requests
import json
from autogen_core import MessageContext, BaseAgent

# Class
class Ollama(BaseAgent):
    def __init__(self) -> None:
        super().__init__(self.__class__.__name__)
        self.msg: Message = Message(origin=self.__class__.__name__)
        
    async def on_message_impl(self, message: Message, ctx: MessageContext) -> None:
        """ Receive a message and send 1 if content is generated by AI, else 0 """
        stp.info(f"Ollama: Received message from {message.origin}")

        # Prepare data for the model
        content: str = str(message.content)
        vote: str = json.loads(message.data).get("request")

        if vote == "majoritaire":
            prompt: str = "Can you simply answer 'Yes' or 'No' if the following sentence has been generated by an AI?"
        elif vote == "borda":
            prompt: str = "Can you classify if the text has been generated by an AI, simply give me the probabilities for each classes between 0 and 1, no explanation ? Answer like this: [human:proba, ai:proba]"

        data: dict = {
            "model": "llama3.2",	# https://ollama.com/download/OllamaSetup.exe
            "prompt": f"{prompt}\n\n{content}",
            "stream": False,
        }
        
        # Request server
        response = requests.post("http://localhost:11434/api/generate", json=data)

        # Vérifier la réponse
        if response.status_code == 200:
            response_data: dict = response.json()
            label: str = response_data["response"].lower()
        else:
            stp.error(f"Erreur lors de la requête : {response.status_code}, {response.text}")

        # If majoritaire
        if vote == "majoritaire":
            label = "".join(x for x in label if x in "abcedfghijklmnopqrstuvwxyz")
            # Get the label result
            labels: dict[str, str] = {"yes": "1", "no": "0", "oui": "1", "non": "0"}
            self.msg.content = labels[label]

        # If borda
        elif vote == "borda":
            # Extract probabilities from label string "[human:0.7, ai:0.3]" -> ["human:0.7", "ai:0.3"]
            probas: list[str] = label[1:-1].split(',')
            
            # Parse probability values for each class
            proba_human: float = float(probas[0].split(':')[1])  # Get human probability
            proba_ai: float = float(probas[1].split(':')[1])     # Get AI probability
            
            # Create list of tuples with class names and probabilities
            probas_tuple: list[tuple[str, float]] = [("human", proba_human), ("ai", proba_ai)]
            
            # Sort by probability in descending order
            probas_tuple.sort(key=lambda x: x[1], reverse=True)
            
            # Build Borda count string - highest probability gets most points
            text: str = ""
            nb_points: int = len(probas_tuple)  # Start with max points
            for candidat, proba in probas_tuple:
                text += f"{candidat} {nb_points},"  # Add "class points," for each
                nb_points -= 1                      # Decrease points for next class

            self.msg.content = text  # Set message content to Borda count string

        # Send back
        await self.send_message(self.msg, ctx.sender)    # type: ignore
        

