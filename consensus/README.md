
# ğŸ¤– SystÃ¨me de Consensus - INFO0909 - SystÃ¨mes Multi-Agents

ğŸ” Ce projet implÃ©mente un systÃ¨me multi-agents pour la dÃ©tection de textes gÃ©nÃ©rÃ©s par IA en utilisant des mÃ©canismes de consensus, construit avec [AutoGen](https://pypi.org/project/autogen-core/) ğŸŒŸ<br>
ğŸ“š Il a Ã©tÃ© dÃ©veloppÃ© dans le cadre de l'unitÃ© d'enseignement INFO0909 - SystÃ¨mes Multi-Agents ğŸ“<br>
ğŸ‘¥ Les auteurs sont :
- [Alexandre COLLIGNON](https://github.com/Stoupy51)
- [Axelle GARRAT](https://github.com/akselZ)

## ğŸ“‹ PrÃ©requis
- Python 3.12 ou plus ğŸ
- [Ollama (pour le modÃ¨le LLM)](https://ollama.com/) ğŸ¦™

## ğŸš€ Installation & DÃ©marrage

1. ğŸ“¥ Cloner le repository
2. ğŸ“¦ Installer les dÃ©pendances (`pip install -r requirements.txt`: optionnel, le main.py installera les dÃ©pendances manquantes)
3. ğŸš€ DÃ©marrer le systÃ¨me avec `python main.py`

## ğŸ—ï¸ Architecture
Le systÃ¨me est composÃ© de plusieurs agents qui communiquent pour atteindre un consensus sur la nature d'un texte (gÃ©nÃ©rÃ© par IA ou non) :

1. **PresidentAgent**: ğŸ¯ Coordonne les votes et agrÃ¨ge les rÃ©sultats en utilisant diffÃ©rents mÃ©canismes de consensus
2. **BERT Agent**: ğŸ§  Utilise le modÃ¨le BERT pour la classification
3. **Ollama Agent**: ğŸ¦™ Utilise le modÃ¨le LLaMA via Ollama pour les prÃ©dictions
4. **Random Agent**: ğŸ² Fait des prÃ©dictions alÃ©atoires comme rÃ©fÃ©rence

## ğŸ—³ï¸ MÃ©canismes de Consensus

Le systÃ¨me implÃ©mente trois mÃ©thodes de vote :

1. **Vote Majoritaire**: DÃ©cision basÃ©e sur la majoritÃ© simple des votes des agents
2. **Vote de Borda**: Vote basÃ© sur les prÃ©fÃ©rences oÃ¹ les agents classent leurs prÃ©dictions
3. **PAXOS**: Protocole de consensus distribuÃ©

## âš™ï¸ Configuration
La configuration du systÃ¨me se fait via le fichier `config.py` qui contient plusieurs composants clÃ©s :

- Chemins et configurations des modÃ¨les
- Emplacement et paramÃ¨tres du dataset
- ParamÃ¨tres de communication des agents
- ParamÃ¨tres des mÃ©canismes de vote

## ğŸ“Š Dataset
Le projet utilise le dataset [AI Vs Human Text](https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text) (5% des donnÃ©es car 487235 lignes est trop grand) de Kaggle pour l'entraÃ®nement et l'Ã©valuation.

