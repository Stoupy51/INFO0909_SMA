
# ğŸ¦ Analyse de Sentiments Twitter/X - INFO0909 - SystÃ¨me Multi-Agents

ğŸ¤– Ce projet implÃ©mente un systÃ¨me multi-agents pour l'analyse de sentiments de tweets en franÃ§ais, en utilisant [SPADE](https://pypi.org/project/spade/) ğŸŒŸ<br>
ğŸ“š Il a Ã©tÃ© dÃ©veloppÃ© dans le cadre de l'unitÃ© d'enseignement INFO0909 - SystÃ¨mes Multi-Agents ğŸ“<br>
ğŸ‘¥ Les auteurs sont :
- [Alexandre COLLIGNON](https://github.com/Stoupy51)
- [Axelle GARRAT](https://github.com/akselZ)


## ğŸ—ï¸ Architecture
Le systÃ¨me est composÃ© de 5 agents qui communiquent entre eux :

1. **CrawlerAgent**: ğŸ” Collecte les tweets via l'API Twitter (twscrape), puis les envoie au **CleanerAgent** si les tweets ne sont pas dÃ©jÃ  dans la base de donnÃ©es.
2. **CleanerAgent**: ğŸ§¹ Nettoie et prÃ©traite les tweets selon les options choisies, puis l'envoie au **LabellerAgent**
3. **LabellerAgent**: ğŸ¤” Analyse le sentiment des tweets via un modÃ¨le LLM (Llama), puis l'envoie au **DatabaseAgent**
4. **DatabaseAgent**: ğŸ’¾ Stocke les rÃ©sultats dans une base de donnÃ©es JSON. Si aucun tweet n'a Ã©tÃ© reÃ§u en 10 secondes, l'agent **SVMAgent** est notifiÃ©.
5. **SVMAgent**: ğŸ“Š Entraine un SVM sur les tweets analysÃ©s et les labels associÃ©s. Puis affiche l'accuracy du modÃ¨le.


## âš™ï¸ Configuration
La configuration du systÃ¨me se fait via le fichier `config.py` qui contient plusieurs classes de configuration :

- `CrawlerConfig`: ğŸ” Configuration de la collecte des tweets `(compte Twitter, nombre max de tweets, requÃªte de recherche)`
- `CleanerConfig`: ğŸ§¹ Options de nettoyage des textes `(suppression des liens, caractÃ¨res spÃ©ciaux, accents, mise en minuscule, stopwords)`
- `LabellerConfig`: ğŸ¯ Configuration du modÃ¨le d'analyse de sentiments `(labels, URL de l'API, modÃ¨le, prompt)`
- `SVMConfig`: ğŸ“ˆ ParamÃ¨tres pour la classification SVM `(nombre max de features, type de kernel, taille du test set, random state)`
- `DatabaseConfig`: ğŸ’½ Configuration de la base de donnÃ©es `(crÃ©ation d'une nouvelle base au dÃ©marrage, fichier)`
- `Agents`: ğŸ”‘ Identifiants et mots de passe des agents SPADE `(crawler, cleaner, database, labeller, svm)`


## ğŸ“‹ PrÃ©requis
- Python 3.8 ou plus ğŸ
- Ollama (pour le modÃ¨le LLM) ğŸ¦™

## ğŸš€ Installation

1. ğŸ“¥ Cloner le repository (`git clone https://github.com/Stoupy51/INFO0909_SMA` par exemple)
2. ğŸ“¦ Installer les dÃ©pendances (`pip install -r requirements.txt`, ou juste `python main.py` qui installera les dÃ©pendances manquantes)
